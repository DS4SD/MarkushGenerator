{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/volume/lum/molecule-depictor-cdk/cdk/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import random\n",
    "import datasets \n",
    "from tqdm import tqdm\n",
    "from datasets import concatenate_datasets\n",
    "from rdkit import Chem, rdBase\n",
    "\n",
    "from mol_depict_cdk.cxsmiles_tokenizer import CXSMILESTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove CXSMILES opt to CXSMILES out conversion errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"ocxsr_3004\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'image_path', 'mol', 'cxsmiles', 'cxsmiles_dataset', 'keypoints', 'cells', 'image', 'cxsmiles_opt'],\n",
      "    num_rows: 217575\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Read for dataloader\n",
    "dataset_hf = concatenate_datasets([\n",
    "    datasets.load_from_disk(os.getcwd() + f\"/../../data/hf_dataset/{dataset_name}/\", keep_in_memory=False)[\"train\"],\n",
    "    datasets.load_from_disk(os.getcwd() + f\"/../../data/hf_dataset/{dataset_name}/\", keep_in_memory=False)[\"test\"]\n",
    "])\n",
    "print(dataset_hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/217575 [00:00<46:52, 77.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 217575/217575 [34:05<00:00, 106.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "i_max = float(\"inf\")\n",
    "verify = False\n",
    "remove_indices = []\n",
    "cxsmiles_tokenizer = CXSMILESTokenizer()\n",
    "for i, sample in tqdm(enumerate(dataset_hf.iter(batch_size=1)), total=min(i_max, len(dataset_hf))):\n",
    "    if i > i_max:\n",
    "        break\n",
    "    id, image, mol, cxsmiles, cxsmiles_dataset, cxsmiles_opt, keypoints, cells = sample[\"id\"][0], sample[\"image\"][0], sample[\"mol\"][0], sample[\"cxsmiles\"][0], sample[\"cxsmiles_dataset\"][0], sample[\"cxsmiles_opt\"][0], sample[\"keypoints\"][0], sample[\"cells\"][0]\n",
    "    \n",
    "    if \"*\" in cxsmiles_opt:\n",
    "        remove_indices.append(i)\n",
    "        continue\n",
    "    if not(verify):\n",
    "        continue\n",
    "    try:\n",
    "        cxsmiles_out = cxsmiles_tokenizer.convert_opt_to_out(cxsmiles_opt)\n",
    "        molecule = Chem.MolFromSmiles(cxsmiles_out)\n",
    "        if molecule is None:\n",
    "            print(cxsmiles_opt)\n",
    "            remove_indices.append(i)\n",
    "            continue\n",
    "    except:\n",
    "        print(\"CXSMILES dataset:\", cxsmiles_dataset)\n",
    "        print(\"CXSMILES CDK:\", cxsmiles)\n",
    "        print(\"CXSMILES optimized:\", cxsmiles_opt)\n",
    "        break\n",
    "print(remove_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'indices'=<generator object <genexpr> at 0x7f8c0219e030> of the transform datasets.arrow_dataset.Dataset.select couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    }
   ],
   "source": [
    "dataset_hf = dataset_hf.select((i for i in range(len(dataset_hf)) if i not in set(remove_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (0/18 shards):   0%|          | 0/195817 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (18/18 shards): 100%|██████████| 195817/195817 [00:36<00:00, 5333.96 examples/s]\n",
      "Saving the dataset (2/2 shards): 100%|██████████| 21758/21758 [00:04<00:00, 5140.24 examples/s]\n"
     ]
    }
   ],
   "source": [
    "hf_dataset_name = \"ocxsr_3005\"\n",
    "dataset_hf = dataset_hf.train_test_split(test_size=0.1)\n",
    "dataset_hf.save_to_disk(os.getcwd() + f\"/../../data/hf_dataset/{hf_dataset_name}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove CXSMILES with multiple Sg sections on the same minimum or maximum atom indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"ocxsr_2001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'image_path', 'mol', 'cxsmiles', 'cxsmiles_dataset', 'cxsmiles_opt', 'keypoints', 'cells', 'image'],\n",
      "    num_rows: 231996\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Read for dataloader\n",
    "dataset_hf = concatenate_datasets([\n",
    "    datasets.load_from_disk(os.getcwd() + f\"/../../data/hf_dataset/{dataset_name}/\", keep_in_memory=False)[\"train\"],\n",
    "    datasets.load_from_disk(os.getcwd() + f\"/../../data/hf_dataset/{dataset_name}/\", keep_in_memory=False)[\"test\"]\n",
    "])\n",
    "print(dataset_hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/231996 [00:00<38:31, 100.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231996/231996 [36:16<00:00, 106.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[89, 472, 1208, 1370, 1431, 1458, 1910, 1982, 2663, 3051, 3449, 3475, 3668, 3988, 4277, 4418, 5398, 5540, 5946, 5994, 6120, 6788, 6860, 7328, 7559, 8196, 8314, 8381, 8576, 8736, 9155, 9385, 9990, 11787, 11893, 12183, 12394, 12918, 13077, 13122, 13131, 13337, 13381, 13385, 13524, 14376, 14978, 15040, 15820, 15826, 15965, 16131, 16206, 16618, 16989, 17111, 17279, 17583, 17909, 18166, 18471, 18542, 18692, 18732, 19017, 19485, 21049, 21866, 21885, 21941, 22035, 23066, 23721, 23788, 23825, 24067, 24165, 24612, 24791, 24883, 24925, 25221, 25313, 25396, 25633, 26299, 26347, 26372, 27233, 27660, 27827, 28791, 28996, 29373, 29578, 30050, 30336, 30343, 30497, 30535, 30577, 31068, 31188, 31313, 31336, 31479, 31696, 31915, 32564, 33291, 33537, 33590, 34185, 34367, 34613, 35059, 35351, 35770, 35934, 36257, 36683, 36910, 37003, 37493, 37988, 38281, 38390, 38420, 38447, 38530, 38763, 38947, 39080, 39224, 39491, 39614, 40532, 40936, 41036, 41121, 41974, 42091, 43013, 44369, 44788, 44973, 45291, 45548, 46091, 46408, 46525, 47247, 47290, 47829, 47890, 48319, 48998, 49179, 49518, 49686, 49807, 50255, 50507, 50813, 51396, 51608, 51858, 51908, 52905, 52966, 53194, 53265, 53397, 53588, 54008, 54198, 54404, 54428, 54510, 54883, 55153, 55169, 55369, 55380, 55539, 55847, 55944, 56229, 56281, 56423, 56949, 57338, 57460, 58101, 58133, 58168, 58836, 58904, 58964, 59683, 59716, 60663, 61227, 61637, 62296, 62894, 63092, 63306, 63602, 63622, 64033, 64144, 64398, 65773, 65922, 65977, 66646, 66922, 66958, 67292, 67294, 67421, 67542, 67600, 67874, 67912, 67983, 69054, 69076, 69367, 69466, 69547, 69957, 70050, 70526, 70738, 70990, 70993, 71064, 71504, 71562, 72099, 72200, 72202, 72491, 72612, 72768, 72832, 72882, 73122, 73538, 73863, 74445, 74696, 75150, 75268, 75387, 75601, 75627, 75752, 76230, 76290, 76391, 76564, 76639, 76703, 76750, 77099, 77220, 77342, 77573, 77612, 77861, 78235, 78429, 78437, 78733, 79012, 79023, 79718, 79816, 79964, 80023, 80265, 80572, 80583, 80622, 80775, 82235, 82326, 82689, 82731, 82839, 83121, 83159, 83358, 83471, 84058, 84902, 85458, 85838, 86422, 86809, 87017, 87078, 87505, 87506, 87851, 88198, 89680, 89767, 89771, 89798, 90390, 90563, 90951, 91083, 91565, 91900, 92250, 92802, 92864, 92974, 93752, 93758, 94010, 94058, 94102, 95262, 95312, 95329, 95731, 95919, 95959, 96280, 96369, 96437, 96704, 97502, 97808, 97888, 97979, 98273, 98595, 98776, 99122, 99133, 99255, 99299, 99580, 99621, 99711, 99712, 99791, 100125, 100201, 100723, 100911, 101106, 101586, 101844, 102178, 102242, 102743, 102887, 102958, 103240, 104112, 104161, 104947, 105128, 105146, 105405, 105518, 105991, 106587, 107204, 107405, 108340, 108529, 108709, 108797, 108823, 109012, 109264, 109370, 109943, 109975, 109981, 110313, 110540, 110808, 110846, 110851, 111113, 111471, 111491, 111728, 111874, 112839, 113483, 113693, 114177, 114470, 115164, 115221, 116026, 116043, 116165, 117215, 117382, 117421, 117598, 118216, 118472, 119165, 119446, 120245, 121660, 122149, 122632, 123194, 123285, 123325, 123907, 124602, 124942, 125567, 125594, 126009, 126795, 127192, 128322, 128523, 128940, 129019, 129163, 129422, 129430, 129444, 129956, 130622, 130695, 131459, 131985, 132265, 132634, 133475, 133515, 133657, 135039, 135290, 135363, 136423, 137378, 137649, 137876, 138004, 138025, 138145, 138790, 139234, 140123, 140696, 140893, 141200, 141328, 141359, 141434, 141561, 141581, 141643, 141888, 142132, 142388, 142463, 143363, 143731, 144029, 144069, 144542, 145612, 145651, 145852, 145867, 145936, 146082, 146257, 146593, 146747, 147265, 147550, 147771, 148102, 148204, 148229, 148247, 149264, 149304, 149484, 149518, 149536, 150123, 150203, 151372, 151621, 152052, 152078, 152121, 152808, 152896, 153157, 153300, 153543, 154024, 154116, 154378, 154570, 155650, 156064, 156073, 156273, 156399, 156428, 156506, 156569, 156591, 156699, 157184, 157550, 157807, 158285, 158336, 158864, 159347, 159564, 159924, 159959, 161197, 161524, 162206, 162627, 164916, 165285, 165527, 165552, 165645, 166313, 166327, 166348, 166484, 166809, 166958, 167938, 168010, 168289, 168746, 168794, 169450, 170286, 171122, 171251, 171611, 171839, 171845, 172154, 172384, 172678, 173293, 173330, 173506, 174702, 174923, 175292, 175971, 176321, 176770, 176893, 176909, 177007, 177282, 177390, 177601, 177991, 178409, 178570, 179331, 181100, 181125, 181206, 182765, 182946, 183253, 183590, 183629, 183725, 184088, 184225, 184427, 184636, 184790, 185090, 185244, 185633, 185789, 185830, 185865, 185999, 186151, 186276, 186406, 186843, 186872, 186910, 186969, 187636, 187773, 188011, 188426, 188901, 189042, 189435, 190327, 190375, 190654, 190698, 193352, 193449, 193608, 193685, 194372, 194448, 194792, 194954, 195071, 196078, 196351, 196617, 196943, 197046, 197475, 198185, 198698, 199402, 199653, 199785, 199824, 200865, 201255, 201652, 201939, 201956, 202026, 202599, 202644, 202843, 203030, 203303, 203554, 204054, 205021, 205093, 205444, 205810, 206098, 206222, 206899, 207166, 207183, 207249, 207480, 207632, 208042, 208195, 208353, 208588, 208652, 208709, 209278, 209530, 209575, 209783, 210425, 210457, 211171, 211523, 212218, 212450, 212672, 213464, 214456, 214676, 214762, 215314, 215913, 215936, 216168, 216991, 217145, 217400, 217439, 217651, 218487, 218992, 219367, 219378, 219644, 219929, 220040, 220095, 220636, 220967, 221537, 221662, 221732, 222182, 222608, 222809, 223154, 223278, 223352, 223491, 223625, 224076, 224245, 224367, 225693, 225795, 225966, 226617, 227250, 227338, 227751, 228369, 228709, 228997, 229156, 229587, 229801, 230102, 230307, 230829, 231445]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "remove_indices = []\n",
    "\n",
    "cxsmiles_tokenizer = CXSMILESTokenizer()\n",
    "for i, sample in tqdm(enumerate(dataset_hf.iter(batch_size=1)), total=min(i_max, len(dataset_hf))):\n",
    "    min_indices, max_indices = [], []\n",
    "    for i_sample, section in enumerate(cxsmiles_tokenizer.parse_sections(sample[\"cxsmiles_dataset\"][0].split(\"|\")[1])):\n",
    "        if (len(section) >= 2) and (section[:2] == \"Sg\"): \n",
    "            sg_section = cxsmiles_tokenizer.parse_sg_section(section)\n",
    "            indices = []\n",
    "            for index in sg_section[2:]:\n",
    "                if index == \"<atom_list_end>\":\n",
    "                    break\n",
    "                if index == \",\":\n",
    "                    continue\n",
    "                indices.append(int(index))\n",
    "            min_index, max_index = min(indices), max(indices)\n",
    "            if (min_index in min_indices) or (max_index in max_indices):\n",
    "                remove_indices.append(i)\n",
    "                break\n",
    "            min_indices.append(min_index)\n",
    "            max_indices.append(max_index)\n",
    "\n",
    "print(remove_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_hf = dataset_hf.select((i for i in range(len(dataset_hf)) if i not in set(remove_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (0/19 shards):   0%|          | 0/208127 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (19/19 shards): 100%|██████████| 208127/208127 [00:40<00:00, 5178.39 examples/s]\n",
      "Saving the dataset (3/3 shards): 100%|██████████| 23126/23126 [00:04<00:00, 5296.37 examples/s]\n"
     ]
    }
   ],
   "source": [
    "hf_dataset_name = \"ocxsr_2002\"\n",
    "dataset_hf = dataset_hf.train_test_split(test_size=0.1)\n",
    "dataset_hf.save_to_disk(os.getcwd() + f\"/../../data/hf_dataset/{hf_dataset_name}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean existing dataset by recomputing cxsmiles opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read for dataloader\n",
    "dataset_name = \"ocxsr_17\"\n",
    "dataset_hf = concatenate_datasets([\n",
    "    datasets.load_from_disk(os.getcwd() + f\"/../../data/hf_dataset/{dataset_name}/\", keep_in_memory=False)[\"train\"],\n",
    "    datasets.load_from_disk(os.getcwd() + f\"/../../data/hf_dataset/{dataset_name}/\", keep_in_memory=False)[\"test\"]\n",
    "])\n",
    "dataset_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_i = float(\"inf\")\n",
    "dataset_name = \"experiment-cx002_cxsmiles_ocr\"\n",
    "cxsmiles_tokenizer = CXSMILESTokenizer()\n",
    "verbose = False\n",
    "new_cxsmiles_opt = []\n",
    "for index, (cxsmiles, cxsmiles_opt, id) in tqdm(enumerate(zip(dataset_hf[\"cxsmiles\"], dataset_hf[\"cxsmiles_opt\"], dataset_hf[\"id\"])), total=len(dataset_hf)):\n",
    "    if index > max_i:\n",
    "        break\n",
    "    # Detect splitted Sg section with more than one comma (ex: Sg:n:1,2,3:l:ht)\n",
    "    detected_error = False\n",
    "    with rdBase.BlockLogs():\n",
    "        parser_params = Chem.SmilesParserParams()\n",
    "        parser_params.strictCXSMILES = False\n",
    "        molecule = Chem.MolFromSmiles(cxsmiles, parser_params)\n",
    "        cxsmiles = Chem.MolToCXSmiles(molecule, canonical=False)\n",
    "\n",
    "    rtable = cxsmiles.split(\"|\")[1]\n",
    "    coordinates = rtable[rtable.find(\"(\"): rtable.find(\")\") + 1]\n",
    "    rtable = rtable.replace(coordinates, \"\")\n",
    "    rtable_opt = \"\"\n",
    "    rtable_split = rtable.split(\",\")\n",
    "    for i, s in enumerate(rtable_split):\n",
    "        if (\"atomProp\" in s):\n",
    "            continue\n",
    "        if s == \"\":\n",
    "            continue\n",
    "        if not(\"Sg\" in s):\n",
    "            continue\n",
    "        if (\"Sg\" in s):\n",
    "            parsed_section = [c for c in s.split(\":\") if c != \"\"]\n",
    "            s = \":\".join(parsed_section)\n",
    "            if len(parsed_section) == 3:\n",
    "                offset = 1\n",
    "                next_index = rtable_split[i + offset]\n",
    "                while len(next_index) == 1:\n",
    "                    s += \",\" + next_index\n",
    "                    offset += 1\n",
    "                    next_index = rtable_split[i + offset]\n",
    "                    if offset >= 2:\n",
    "                        detected_error = True\n",
    "    if not(detected_error):\n",
    "        new_cxsmiles_opt.append(cxsmiles_opt)\n",
    "        continue\n",
    "    \n",
    "    molfile_path = os.getcwd() + f\"/../../data/dataset/{dataset_name}/molfiles/{id}.mol\"\n",
    "    with rdBase.BlockLogs():\n",
    "        molecule = Chem.MolFromMolFile(molfile_path, strictParsing=False, removeHs=False)\n",
    "    if molecule is None:\n",
    "        if verbose:\n",
    "            print(\"Invalid CXSMILES from MOLfile\")\n",
    "        continue\n",
    "    cxsmiles = Chem.MolToCXSmiles(molecule)\n",
    "    mol_to_cxsmi_i_mapping = {k: v for k, v in zip(\n",
    "        list(map(int, molecule.GetProp(\"_smilesAtomOutputOrder\")[1:-2].split(\",\"))),\n",
    "        range(0, molecule.GetNumAtoms()),\n",
    "    )}\n",
    "    \n",
    "    cxsmiles_opt, keypoints = cxsmiles_tokenizer.convert_cdk_to_opt(cxsmiles, molfile_path, mol_to_cxsmi_i_mapping)\n",
    "\n",
    "    new_cxsmiles_opt.append(cxsmiles_opt)\n",
    "    if verbose:\n",
    "        print(f\"Problem fixed for {index, id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_hf = dataset_hf.remove_columns(\"cxsmiles_opt\").add_column(\"cxsmiles_opt\", new_cxsmiles_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (5/5 shards): 100%|██████████| 53790/53790 [00:53<00:00, 1009.17 examples/s]\n",
      "Saving the dataset (2/2 shards): 100%|██████████| 13448/13448 [00:03<00:00, 4442.88 examples/s]\n"
     ]
    }
   ],
   "source": [
    "hf_dataset_name = \"ocxsr_18\"\n",
    "dataset_hf = dataset_hf.train_test_split(test_size=0.2)\n",
    "dataset_hf.save_to_disk(os.getcwd() + f\"/../../data/hf_dataset/{hf_dataset_name}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean existing dataset by recomputing cxsmiles opt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'image', 'mol', 'cxsmiles', 'cxsmiles_dataset', 'keypoints', 'cxsmiles_opt', 'celss'],\n",
       "    num_rows: 67238\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read for dataloader\n",
    "dataset_name = \"ocxsr_17\"\n",
    "dataset_hf = concatenate_datasets([\n",
    "    datasets.load_from_disk(os.getcwd() + f\"/../../data/hf_dataset/{dataset_name}/\", keep_in_memory=False)[\"train\"],\n",
    "    datasets.load_from_disk(os.getcwd() + f\"/../../data/hf_dataset/{dataset_name}/\", keep_in_memory=False)[\"test\"]\n",
    "])\n",
    "dataset_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_i = float(\"inf\")\n",
    "dataset_name = \"experiment-cx002_cxsmiles_ocr\"\n",
    "cxsmiles_tokenizer = CXSMILESTokenizer()\n",
    "verbose = True\n",
    "new_cxsmiles_opt = []\n",
    "for index, (cxsmiles, cxsmiles_opt, id) in tqdm(enumerate(zip(dataset_hf[\"cxsmiles\"], dataset_hf[\"cxsmiles_opt\"], dataset_hf[\"id\"])), total=len(dataset_hf)):\n",
    "    if index > max_i:\n",
    "        break\n",
    "    molfile_path = os.getcwd() + f\"/../../data/dataset/{dataset_name}/molfiles/{id}.mol\"\n",
    "    with rdBase.BlockLogs():\n",
    "        molecule = Chem.MolFromMolFile(molfile_path, strictParsing=False, removeHs=False)\n",
    "    if molecule is None:\n",
    "        print(\"Invalid CXSMILES from MOLfile\")\n",
    "        break\n",
    "    \n",
    "    cxsmiles = Chem.MolToCXSmiles(molecule)\n",
    "    mol_to_cxsmi_i_mapping = {k: v for k, v in zip(\n",
    "        list(map(int, molecule.GetProp(\"_smilesAtomOutputOrder\")[1:-2].split(\",\"))),\n",
    "        range(0, molecule.GetNumAtoms()),\n",
    "    )}\n",
    "    \n",
    "    cxsmiles_opt, keypoints = cxsmiles_tokenizer.convert_cdk_to_opt(cxsmiles, molfile_path, mol_to_cxsmi_i_mapping)\n",
    "\n",
    "    # Check that Sg section\n",
    "    gt_smiles = cxsmiles_tokenizer.convert_opt_to_out(cxsmiles_opt)\n",
    "    \n",
    "    canonical_smiles = canonicalize_markush(gt_smiles)\n",
    "    if \"eu\" in canonical_smiles:\n",
    "        print(\"index:\", index)\n",
    "        print(\"cxsmiles_opt:\", cxsmiles_opt)\n",
    "        print(\"cxsmiles:\", cxsmiles)\n",
    "\n",
    "        cxsmiles_opt, keypoints = cxsmiles_tokenizer.convert_cdk_to_opt(cxsmiles, molfile_path, mol_to_cxsmi_i_mapping, verbose=True)\n",
    "        break\n",
    "\n",
    "    new_cxsmiles_opt.append(cxsmiles_opt)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_hf = dataset_hf.remove_columns(\"cxsmiles_opt\").add_column(\"cxsmiles_opt\", new_cxsmiles_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (5/5 shards): 100%|██████████| 53790/53790 [00:32<00:00, 1633.96 examples/s]\n",
      "Saving the dataset (2/2 shards): 100%|██████████| 13448/13448 [00:02<00:00, 4822.16 examples/s]\n"
     ]
    }
   ],
   "source": [
    "hf_dataset_name = \"ocxsr_20\"\n",
    "dataset_hf = dataset_hf.train_test_split(test_size=0.2)\n",
    "dataset_hf.save_to_disk(os.getcwd() + f\"/../../data/hf_dataset/{hf_dataset_name}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean existing dataset by recomputing cxsmiles opt 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'image_path', 'mol', 'cxsmiles', 'cxsmiles_dataset', 'keypoints', 'cells', 'image', 'cxsmiles_opt'],\n",
       "    num_rows: 217575\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read for dataloader\n",
    "dataset_name = \"ocxsr_3003\"\n",
    "dataset_hf = concatenate_datasets([\n",
    "    datasets.load_from_disk(os.getcwd() + f\"/../../data/hf_dataset/{dataset_name}/\", keep_in_memory=False)[\"train\"],\n",
    "    datasets.load_from_disk(os.getcwd() + f\"/../../data/hf_dataset/{dataset_name}/\", keep_in_memory=False)[\"test\"]\n",
    "])\n",
    "dataset_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 217575/217575 [07:43<00:00, 469.45it/s]\n"
     ]
    }
   ],
   "source": [
    "max_i = float(\"inf\")\n",
    "dataset_name = \"experiment-cx3000_cxsmiles_ocr\"\n",
    "cxsmiles_tokenizer = CXSMILESTokenizer()\n",
    "verbose = True\n",
    "new_cxsmiles_opt = []\n",
    "for index, (cxsmiles, cxsmiles_opt, id) in tqdm(enumerate(zip(dataset_hf[\"cxsmiles\"], dataset_hf[\"cxsmiles_opt\"], dataset_hf[\"id\"])), total=len(dataset_hf)):\n",
    "    if index > max_i:\n",
    "        break\n",
    "    molfile_path = os.getcwd() + f\"/../../data/dataset/{dataset_name}/molfiles/{id}.mol\"\n",
    "    with rdBase.BlockLogs():\n",
    "        molecule = Chem.MolFromMolFile(molfile_path, strictParsing=False, removeHs=False)\n",
    "    if molecule is None:\n",
    "        print(\"Invalid CXSMILES from MOLfile\")\n",
    "        break\n",
    "    \n",
    "    cxsmiles = Chem.MolToCXSmiles(molecule)\n",
    "    mol_to_cxsmi_i_mapping = {k: v for k, v in zip(\n",
    "        list(map(int, molecule.GetProp(\"_smilesAtomOutputOrder\")[1:-2].split(\",\"))),\n",
    "        range(0, molecule.GetNumAtoms()),\n",
    "    )}\n",
    "    \n",
    "    cxsmiles_opt, keypoints = cxsmiles_tokenizer.convert_cdk_to_opt(cxsmiles, molfile_path, mol_to_cxsmi_i_mapping)\n",
    "\n",
    "    new_cxsmiles_opt.append(cxsmiles_opt)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_hf = dataset_hf.remove_columns(\"cxsmiles_opt\").add_column(\"cxsmiles_opt\", new_cxsmiles_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (16/16 shards): 100%|██████████| 174060/174060 [01:59<00:00, 1452.10 examples/s]\n",
      "Saving the dataset (4/4 shards): 100%|██████████| 43515/43515 [00:08<00:00, 4949.25 examples/s]\n"
     ]
    }
   ],
   "source": [
    "hf_dataset_name = \"ocxsr_3004\"\n",
    "dataset_hf = dataset_hf.train_test_split(test_size=0.2)\n",
    "dataset_hf.save_to_disk(os.getcwd() + f\"/../../data/hf_dataset/{hf_dataset_name}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'image', 'mol', 'cxsmiles', 'cxsmiles_dataset', 'keypoints', 'cells', 'cxsmiles_opt'],\n",
       "    num_rows: 67238\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read for dataloader\n",
    "dataset_name = \"ocxsr_16\"\n",
    "dataset_hf = concatenate_datasets([\n",
    "    datasets.load_from_disk(os.getcwd() + f\"/../../data/hf_dataset/{dataset_name}/\", keep_in_memory=False)[\"train\"],\n",
    "    datasets.load_from_disk(os.getcwd() + f\"/../../data/hf_dataset/{dataset_name}/\", keep_in_memory=False)[\"test\"]\n",
    "])\n",
    "dataset_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_i = float(\"inf\")\n",
    "\n",
    "new_cells_list = []\n",
    "for index, cells in enumerate(dataset_hf[\"cells\"]):   \n",
    "    if index > max_i:\n",
    "        break\n",
    "    random.shuffle(cells)\n",
    "    new_cells_list.append(cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_hf = dataset_hf.remove_columns(\"cells\").add_column(\"cells\", new_cells_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (0/5 shards):   0%|          | 0/53790 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (5/5 shards): 100%|██████████| 53790/53790 [00:09<00:00, 5740.62 examples/s]\n",
      "Saving the dataset (2/2 shards): 100%|██████████| 13448/13448 [00:02<00:00, 6019.18 examples/s]\n"
     ]
    }
   ],
   "source": [
    "hf_dataset_name = \"ocxsr_17\"\n",
    "dataset_hf = dataset_hf.train_test_split(test_size=0.2)\n",
    "dataset_hf.save_to_disk(os.getcwd() + f\"/../../data/hf_dataset/{hf_dataset_name}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename column \"cells\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'image', 'mol', 'cxsmiles', 'cxsmiles_dataset', 'keypoints', 'celss', 'cxsmiles_opt'],\n",
       "    num_rows: 67238\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read for dataloader\n",
    "dataset_name = \"ocxsr_20\"\n",
    "dataset_hf = concatenate_datasets([\n",
    "    datasets.load_from_disk(os.getcwd() + f\"/../../data/hf_dataset/{dataset_name}/\", keep_in_memory=False)[\"train\"],\n",
    "    datasets.load_from_disk(os.getcwd() + f\"/../../data/hf_dataset/{dataset_name}/\", keep_in_memory=False)[\"test\"]\n",
    "])\n",
    "dataset_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_hf = dataset_hf.rename_column(\"celss\", \"cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (0/5 shards):   0%|          | 0/53790 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (5/5 shards): 100%|██████████| 53790/53790 [00:12<00:00, 4200.27 examples/s]\n",
      "Saving the dataset (2/2 shards): 100%|██████████| 13448/13448 [00:03<00:00, 4405.02 examples/s]\n"
     ]
    }
   ],
   "source": [
    "hf_dataset_name = \"ocxsr_21\"\n",
    "dataset_hf = dataset_hf.train_test_split(test_size=0.2)\n",
    "dataset_hf.save_to_disk(os.getcwd() + f\"/../../data/hf_dataset/{hf_dataset_name}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recompute cxsmiles opt to remove R-group injection (Ablation study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'page_image_path', 'description', 'annotation', 'mol', 'cxsmiles_dataset', 'cxsmiles', 'cxsmiles_opt', 'keypoints', 'cells', 'page_image'],\n",
       "    num_rows: 235570\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read for dataloader\n",
    "dataset_name = \"mdu_3008_aug\"\n",
    "dataset_hf = concatenate_datasets([\n",
    "    datasets.load_from_disk(os.getcwd() + f\"/../../../deepsearch-ai-unidoc/data/{dataset_name}/\", keep_in_memory=False)[\"train\"],\n",
    "    datasets.load_from_disk(os.getcwd() + f\"/../../../deepsearch-ai-unidoc/data/{dataset_name}/\", keep_in_memory=False)[\"test\"]\n",
    "])\n",
    "dataset_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235570/235570 [07:37<00:00, 514.78it/s]\n"
     ]
    }
   ],
   "source": [
    "max_i = float(\"inf\")\n",
    "dataset_name = \"experiment-cx3000_cxsmiles_ocr\"\n",
    "cxsmiles_tokenizer = CXSMILESTokenizer(condense_labels = False)\n",
    "verbose = False\n",
    "new_cxsmiles_opt = []\n",
    "for index, (cxsmiles, cxsmiles_opt, id) in tqdm(enumerate(zip(dataset_hf[\"cxsmiles\"], dataset_hf[\"cxsmiles_opt\"], dataset_hf[\"id\"])), total=len(dataset_hf)):\n",
    "    if index > max_i:\n",
    "        break\n",
    "   \n",
    "    molfile_path = os.getcwd() + f\"/../../data/dataset/{dataset_name}/molfiles/{id}.mol\"\n",
    "    with rdBase.BlockLogs():\n",
    "        molecule = Chem.MolFromMolFile(molfile_path, strictParsing=False, removeHs=False)\n",
    "    if molecule is None:\n",
    "        if verbose:\n",
    "            print(\"Invalid CXSMILES from MOLfile\")\n",
    "        continue\n",
    "    cxsmiles = Chem.MolToCXSmiles(molecule)\n",
    "    mol_to_cxsmi_i_mapping = {k: v for k, v in zip(\n",
    "        list(map(int, molecule.GetProp(\"_smilesAtomOutputOrder\")[1:-2].split(\",\"))),\n",
    "        range(0, molecule.GetNumAtoms()),\n",
    "    )}\n",
    "    #cxsmiles_out = cxsmiles_tokenizer.convert_opt_to_out(cxsmiles_opt, condensed_labels=True)\n",
    "    cxsmiles_opt, keypoints = cxsmiles_tokenizer.convert_cdk_to_opt(cxsmiles, molfile_path, mol_to_cxsmi_i_mapping)\n",
    "    new_cxsmiles_opt.append(cxsmiles_opt)    \n",
    "    \n",
    "    #cxsmiles_out = cxsmiles_tokenizer.convert_opt_to_out(cxsmiles_opt)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Problem fixed for {index, id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_hf = dataset_hf.remove_columns(\"cxsmiles_opt\").add_column(\"cxsmiles_opt\", new_cxsmiles_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (45/45 shards): 100%|██████████| 188456/188456 [05:58<00:00, 525.19 examples/s] \n",
      "Saving the dataset (12/12 shards): 100%|██████████| 47114/47114 [00:42<00:00, 1109.74 examples/s]\n"
     ]
    }
   ],
   "source": [
    "hf_dataset_name = \"mdu_3008_aug_no_condense\"\n",
    "dataset_hf = dataset_hf.train_test_split(test_size=0.2)\n",
    "dataset_hf.save_to_disk(os.getcwd() + f\"/../../data/hf_dataset/{hf_dataset_name}/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdk",
   "language": "python",
   "name": "cdk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
